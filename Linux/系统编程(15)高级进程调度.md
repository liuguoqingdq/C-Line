# 第6章 高级进程管理（6.1–6.7）详细讲解

这一章的关键词是：**“谁运行、运行多久、在哪个 CPU 上跑、遇到竞争怎么让、以及系统如何限制进程消耗资源”**。

从系统编程角度，建议你把它拆成两条主线：
1) **调度相关**：策略（policy）+ 优先级（priority）+ 让出 CPU（yield）+ CPU 亲和性（affinity）+ 实时（RT）
2) **资源治理**：rlimit / ulimit（以及更现代的 cgroups）

---

## 6.1 进程调度（Scheduling）[[linux进程调度]]

### 6.1.1 你必须先建立的调度模型
Linux 的调度要解决两个问题：
- **选择谁运行**：从 runnable（可运行）队列里挑一个任务
- **什么时候切换**：时间片用完、任务阻塞、被抢占、更高优先级到来等

在现代 Linux（多核）里，每个 CPU 都有自己的运行队列（runqueue），核心思路是：
- 尽量让任务在**本地 CPU** 上运行（减少迁移成本、cache 热度更好）
- 必要时做负载均衡（load balancing）

### 6.1.2 调度类（sched class）与调度策略（policy）
从“用户态能选择什么”的角度，你常接触到的策略是：
- **普通进程**：`SCHED_OTHER`（也叫 CFS 体系）
- **批处理**：`SCHED_BATCH`（更少抢占/更偏吞吐）
- **极低优先**：`SCHED_IDLE`
- **实时**：`SCHED_FIFO`、`SCHED_RR`
- **截止期**：`SCHED_DEADLINE`（更高级，常见于特定 RT 场景）

系统编程常用 API：
```c
#include <sched.h>
int sched_getscheduler(pid_t pid);
int sched_setscheduler(pid_t pid, int policy, const struct sched_param *param);
int sched_setparam(pid_t pid, const struct sched_param *param);
int sched_getparam(pid_t pid, struct sched_param *param);
int sched_get_priority_max(int policy);
int sched_get_priority_min(int policy);
```

> 记住：**policy 决定“规则”，priority/nice 决定“在规则内的位置”**。

### 6.1.3 普通程序如何“观察”调度状态
- `ps -o pid,cls,pri,ni,stat,psr,comm -p <pid>`：看调度类、优先级、nice、跑在哪个 CPU
- `top/htop`：观察 NI/PR
- `chrt -p <pid>`：查看/设置实时策略

---

## 6.2 完全公平调度器（CFS, Completely Fair Scheduler）

### 6.2.1 CFS 想“公平”什么？
CFS 服务的对象主要是 **普通进程**（`SCHED_OTHER` 等）。它的公平是：
- **按权重分配 CPU 时间**：权重由 `nice` 间接决定
- 目标：在足够长时间窗口内，每个任务获得的 CPU 时间 ≈ 它应得的份额

### 6.2.2 核心概念：`vruntime`（虚拟运行时间）
CFS 不直接用“真实运行时间”排序，而是用 `vruntime`：
- 任务跑得越多 → `vruntime` 增长越多
- **权重越高（nice 越小）** → 同样跑一段真实时间，`vruntime` 增长得更慢

因此：
- CFS 总是挑 **vruntime 最小** 的任务运行（“亏欠最多的人先跑”）

### 6.2.3 数据结构：红黑树（RB-tree）
可运行任务以 `vruntime` 为 key 放入红黑树：
- 取最小 vruntime：树的最左节点（O(logN) 插入/删除）
- 这比传统 O(N) 遍历更适合大量任务

### 6.2.4 时间片不是固定的：由目标延迟与最小粒度控制
传统调度器常用固定时间片；CFS 更像：
- 设一个“目标调度延迟”（target latency）：希望在这个时间里让所有 runnable 任务至少跑一次
- 但同时又受“最小粒度”（min granularity）约束，避免任务太多导致每个任务时间片小到不可用

### 6.2.5 nice 的意义
`nice` 影响权重，从而影响“你占 CPU 的份额”。
- nice 值范围通常是 **-20（更优先）到 +19（更不优先）**
- 普通用户通常只能把 nice 调大（变“更友好”），降低 nice（更抢资源）需要权限

常见 API：
```c
#include <sys/time.h>
#include <sys/resource.h>
int getpriority(int which, id_t who);
int setpriority(int which, id_t who, int prio);
```

> 注意：`getpriority` 返回值范围与 errno 的交互容易踩坑（-1 可能是合法值，需先清 errno 再调用）。

---

## 6.3 让出处理器（Yield）

### 6.3.1 “让出”是什么意思
让出 CPU 是一种 **自愿放弃当前可运行资格的行为**，常用于：
- 你在忙等，但希望别把 CPU 占满
- 你是低优先级线程，愿意让其他线程先跑

Linux 常用接口：
```c
#include <sched.h>
int sched_yield(void);
```

### 6.3.2 `sched_yield()` 的真实效果（要讲清楚）
`sched_yield()` 并不是“睡一会儿”，而是：
- **把当前任务放回其调度队列尾部（或相应位置）**，触发一次重新挑选
- 若系统里没有更合适的可运行任务，你可能**马上又被选中**（因此它不保证你会“让出很久”）

### 6.3.3 什么时候不该用 yield
- 用 yield 解决同步问题通常是“坏味道”：正确做法是 mutex/condvar/futex/epoll 等阻塞式等待
- yield 可能导致：
  - 无谓的上下文切换
  - CPU 利用率异常
  - 在实时调度下产生意外的调度行为

### 6.3.4 更推荐的替代
- 等待事件：`pthread_cond_wait` / `futex` / `epoll_wait` / `select/poll`
- 需要“轻量退让”时：短自旋 + `nanosleep` 或 “自旋次数超阈值后阻塞”

---

## 6.4 进程优先级（Priority）
[[linux进程优先级]]
Linux 里“优先级”有两套体系，必须分清：

### 6.4.1 普通优先级：nice（影响 CFS 权重）
- 适用于 `SCHED_OTHER/BATCH/IDLE`
- nice 不是“硬优先级”，而是“份额权重”

工具：
- `nice -n 10 cmd`：以更低优先级启动
- `renice +5 -p <pid>`：调整正在运行的进程 nice

### 6.4.2 实时优先级：RT priority（1–99）
- 适用于 `SCHED_FIFO`、`SCHED_RR`
- 这是“硬优先级”：高 RT priority 进程会抢占低的

API：
```c
#include <sched.h>
struct sched_param sp = {.sched_priority = 50};
sched_setscheduler(pid, SCHED_FIFO, &sp);
```

> 现实警告：RT 优先级用不好会让系统“卡死感”明显（低优先级任务得不到运行机会）。

### 6.4.3 `SCHED_RR` vs `SCHED_FIFO`
- `SCHED_FIFO`：同优先级下，谁先运行谁一直跑，除非阻塞/主动让出/被更高优先级抢占
- `SCHED_RR`：同优先级下按时间片轮转，更“公平”一些

---

## 6.5 处理器亲和力（CPU Affinity）

### 6.5.1 亲和力是什么
CPU 亲和力就是：**处理器亲和力（processor affinity）表明一个进程会一直被调度到同一处理器上的可能性。术语“软亲和力（soft affinity）”表明调度器持续调度进程到同一处理器上的自然倾向，从上文的讨论可以看到，这是非常有价值的特性。Linux调度器尽可能地这样做，只有当负载极端不平衡的时候，才考虑迁移进程，从而，最小化迁移的缓存效应，还能保证系统中的处理器负载基本平衡。

但是，有些时候，用户或者应用需要保证进程和处理器间的绑定，这通常发生在进程非常依赖缓存（cache-sensitive），期望能够在同一个处理器下运行。把进程绑定到特定处理器并强制内核保证这种绑定关系，这称为“**硬亲和力（hard affinity）”。 

Linux在单个系统中支持多处理器，除了启动进程，支持多处理器的大多数工作都依赖于进程调度器。在多处理机上，进程调度器必须决定在每个CPU上运行哪个进程。 

 因此，**必须解决两大难题**：调度器必须尽量充分利用系统的处理器，因为当某个进程在等待运行时有个CPU空闲，性能就不会很高。但是，如果一个进程曾在某一CPU上运行，后面再运行时，进程调度器还应该尽量把它再放到同一个CPU上，因为处理器间的进程迁移会带来性能损失。 
 
 处理器间的进程迁移最大的性能损失来自于“缓存效应（cache effects）”。现代对称多处理（SMP）系统的设计中，每个处理器的缓存是各自独立的，而且相互不同。也就是说，处理器并不共享缓存中的数据。因此，当进程迁移到新处理器上后写入新数据到内存时，原有处理器的缓存就过期了，如果依赖原来这份缓存可能会带来损坏。

处理器间的进程迁移最大的性能损失来自于“缓存效应（cache effects）”。现代对称多处理（SMP）系统的设计中，每个处理器的缓存是各自独立的，而且相互不同。也就是说，处理器并不共享缓存中的数据。因此，当进程迁移到新处理器上后写入新数据到内存时，原有处理器的缓存就过期了，如果依赖原来这份缓存可能会带来损坏（corruption）。为了避免这种情况，缓存读入新的一块内存数据时会标记其他缓存无效。因此，在任意时刻，任意数据仅在一个处理器的缓存中有效（假设该数据被缓存）。因此，当进程在处理器间迁移时，就会带来两方面的代价：一是进程不再能访问缓存数据，二是原处理器的缓存中的数据必须标记为无效。考虑到这些代价，进程调度器会尽量让进程尽可能在固定的某个处理器上运行。

当然，进程调度器的两个目标有潜在的冲突。如果一个处理器比另一个处理器的负载大得多——或者更糟的是，如果一个处理器很忙而另一个空闲——这样，把某些进程重新调度到不忙碌的CPU上就很有意义。决定何时移动进程来避免不平衡，称为负载均衡，对SMP机器的性能至关重要。

为什么要做亲和力？
- cache 热度：固定在某核上，缓存命中更好
- 减少迁移：线程迁移会带来 cache/TLB 失效
- NUMA：把线程绑到靠近内存的节点上能显著影响延迟
- 隔离：把 noisy 任务绑到某些核，把关键任务留在其它核

### 6.5.2 系统调用接口
```c
#define _GNU_SOURCE
#include <sched.h>

int sched_setaffinity(pid_t pid, size_t cpusetsize, const cpu_set_t *mask);
int sched_getaffinity(pid_t pid, size_t cpusetsize, cpu_set_t *mask);
```
- `sched_setaffinity()`：设置指定进程的 CPU 允许集合（mask）
    
- `sched_getaffinity()`：读取指定进程当前的 CPU 允许集合（mask）

常见宏：
```c
CPU_ZERO(&set);
CPU_SET(3, &set);
CPU_ISSET(3, &set);
```
#### 3) 参数逐个解释

### (1) `pid`

- 指定要操作的进程（更准确：在 Linux 上是“线程组/任务”的对象；但接口以 pid 表示）
    
- `pid == 0`：表示**当前调用进程/线程**（常用）
    

### (2) `cpusetsize`

- `mask` 指向的 `cpu_set_t` 结构体的**字节大小**
    
- 通常写：`sizeof(cpu_set_t)`
    
- 作用：让内核知道你给的位图多大，避免越界读写
    

> 注意：如果机器 CPU 数很多（比如 > CPU_SETSIZE），需要用动态 CPU 集合（`CPU_ALLOC/CPU_ALLOC_SIZE`），这时 `cpusetsize` 就不是 `sizeof(cpu_set_t)` 了，而是你分配的大小。

### (3) `mask`

- 指向一个 `cpu_set_t` 位图，表示允许的 CPU 集合
    
- 常用宏操作它：
    
    - `CPU_ZERO(&set)` 清空
        
    - `CPU_SET(cpu, &set)` 把某个 cpu 加进去
        
    - `CPU_CLR(cpu, &set)` 移除
        
    - `CPU_ISSET(cpu, &set)` 判断是否在集合内

#### 4) 返回值是什么？

两者返回值规则一样：

- **成功**：返回 `0`
    
- **失败**：返回 `-1`，并设置 `errno`
    

常见 `errno`：

- `EINVAL`：`cpusetsize` 不合法，或 mask 为空/CPU 不存在（比如设置了超出范围的 CPU 位）
    
- `EPERM`：没有权限修改别的进程的亲和性（或不允许的操作）
    
- `ESRCH`：`pid` 对应的进程不存在
    

---

## 5) 最小示例：读取并设置亲和性

### 读取当前进程允许在哪些 CPU 上跑

```C
cpu_set_t set;
CPU_ZERO(&set);

if (sched_getaffinity(0, sizeof(set), &set) == -1) {
    perror("sched_getaffinity");
}
for (int i = 0; i < CPU_SETSIZE; i++) {
    if (CPU_ISSET(i, &set)) {
        printf("allowed cpu: %d\n", i);
    }
}
```

**把当前进程限制到 CPU 0 和 CPU 2:

```C
cpu_set_t set;
CPU_ZERO(&set);
CPU_SET(0, &set);
CPU_SET(2, &set);

if (sched_setaffinity(0, sizeof(set), &set) == -1) {
    perror("sched_setaffinity");
}
```

-----
命令行工具：
- `taskset -p <mask> <pid>`
- `taskset -c 0,2,4 cmd`

### 6.5.3 线程亲和性（pthread）
很多场景你是线程级控制：
- `pthread_setaffinity_np()`（非标准但常见）

### 6.5.4 工程注意点
- 绑核并不总是更快：绑得不合理会导致某核过载、负载均衡失效
- 服务器程序常用策略：
  - I/O 线程与 worker 线程分离
  - 关键线程绑“干净核”，把噪声任务放到其它核

---

## 6.6 实时系统（Real-time）

 **在计算机领域，术语“实时”往往很容易引起困惑和误解。如果一个系统受限于“操作时限（operational deadlines）”，即请求和响应之间的最少且必须执行的次数，就称该系统是“实时系统”。一个常见的“实时系统”是“防抱死（ABS）”系统，几乎在所有的现代机动车都能够看到它。在这个系统中，当踩下刹车时，计算机会调节刹车压力，一般是通过在一秒内多次施加和释放最大刹车压力，以防止轮胎“锁死”，降低刹车动力，避免汽车失控。在这种系统中，系统的“操作时限”是指系统能够多快地响应轮胎“锁死”，能够多快地施加刹车压力。

### 延迟、抖动和截止期限

## 1）延迟（Latency）在调度里指什么？

调度语境里最常说的是 **调度延迟（scheduling latency）**：

> 一个任务已经“应该能跑了”（runnable），但它真正开始在 CPU 上执行之间的等待时间。

更细拆成两类你会经常看到：

### A. 唤醒延迟（wakeup latency）

任务从阻塞（sleep/等待 I/O/等待锁）被唤醒 → 进入 runnable 队列 → **直到真正被调度上 CPU** 的时间。  
常见于：网络包到达唤醒线程、条件变量唤醒线程、定时器到点唤醒线程。

### B. 抢占延迟（preemption latency）

更高优先级任务变 runnable 了，但当前 CPU 上正在跑的任务**没有立刻让出**（或内核暂时不可抢占）导致的延迟。  
常见于：实时/低延迟任务被普通任务、内核临界区、关中断等拖慢。

> 直觉：**latency = “我本该跑”到“我真正开始跑”的时间差**。

---

## 2）抖动（Jitter）在调度里指什么？

调度语境里抖动就是：

> 同一类任务、同一种触发方式下，调度延迟（或被调度到的时间点）**不稳定、波动很大**。

如果你一个周期任务每 1ms 应该运行一次：

- 有时晚 5µs
    
- 有时晚 200µs
    
- 偶尔晚 3ms  
    这种“晚多少”的波动就是抖动。
    

**抖动关注的不是平均值，而是波动/尾部**（max、P99、P999）。  
很多系统“平均延迟不大，但偶发很大”就是抖动问题。

常见抖动来源（调度角度）：

- runqueue 上竞争任务数量变化（队列等待时间变）
    
- CPU 迁移（cache/TLB 冷导致执行起步慢、以及迁移引入额外等待）
    
- 中断/软中断挤占 CPU
    
- 锁竞争/优先级反转（高优先级被低优先级拿锁卡住）
    
- 内核不可抢占区间、长临界区
    

---

## 3）截止期限（Deadline）在调度里指什么？

deadline 在调度里不是“希望快点”，而是一个**硬时间约束**：

> 对某次任务实例（job），从释放时刻 release 开始，到某个最晚时间点 D 之前，必须得到足够的 CPU 执行（或必须完成）。

- 如果在 D 前没跑够/没完成：**deadline miss**（超期）
    
- 这是“可预测性”问题，不是“平均性能”问题
    

### 在 Linux 调度策略里的对应关系

- **CFS（SCHED_OTHER）**：主要目标是公平与吞吐，对 deadline **没有严格保证**；它的 `target_latency` 更像“期望的调度窗口”，不是硬 deadline。
    
- **实时（SCHED_FIFO/RR）**：用“硬优先级”来降低高优任务的等待，从而更容易满足 deadline（但用不好会饿死别人）。
    
- **SCHED_DEADLINE**：直接把任务建模成 `(runtime, period, deadline)`：
    
    - `runtime`：每周期需要的 CPU 预算
        
    - `period`：周期
        
    - `deadline`：周期内最晚完成点  
        调度器目标就是尽量避免 miss（这才是“deadline”在 Linux 里最字面化的体现）。
        

---

## 一句话把三者关系串起来

- **Latency**：某次该跑→实际开始跑，差了多少
    
- **Jitter**：这个“差了多少”是否稳定、尾部是否会炸
    
- **Deadline**：差再大也不能超过某个底线，否则就是 miss


-----
### 6.6.1 实时的真正含义
“实时”不是“更快”，而是：
- **可预测**：在限定时间内完成（deadline）
- 关注的是延迟上界（worst-case latency），而不是平均性能

Linux 提供“软实时”能力：
- 普通内核也能做一定实时，但不保证极端条件下的严格上界
- PREEMPT_RT 补丁/实时内核可进一步改善（更强实时性）

### 6.6.2 实时调度策略
- `SCHED_FIFO` / `SCHED_RR`：经典 RT
- `SCHED_DEADLINE`：按运行时间/周期/截止期建模（更先进）

### 6.6.3 实时程序的常见工程措施
1) **优先级设计**：
- 关键路径任务高优先级
- 低优先级任务必须能让路

2) **避免缺页/换页抖动**：
- 用 `mlockall(MCL_CURRENT | MCL_FUTURE)` 锁内存（防止页被换出）

3) **减少不可控阻塞**：
- 避免在 RT 线程里做 IO、malloc、锁粒度过大
- 采用无锁结构或短临界区

4) **防止饿死（starvation）**：
- RT 线程可能让普通线程长期得不到 CPU
- 需要谨慎设置 RT priority、并考虑 watchdog/超时

### 6.6.4 常用工具
- `chrt`：查看/设置实时策略与优先级
- `cyclictest`（在 RT 评估里常见）：测调度延迟

### Linux调度策略和优先级

Linux对进程的调度行为依赖于进程的调度策略，也称为调度类别（scheduling class）。除了正常的默认策略，Linux还提供了两种实时调度策略。头文件<sched.h>中的预处理器宏表示各个策略：分别是SCHED_FIFO、SCHED_RR和SCHED_ OTHER。 
 每个进程都持有一个静态优先级，该优先级和nice value无关。对于普通应用，静态优先级的值为0；对于实时应用，其值为1到99。Linux调度器总是选择优先级最高的进程运行（即静态优先级值最大的进程）。如果一个正在运行的进程，其优先级值为50，当优先级为51的进程就绪时，调度器会立即直接抢占当前进程，转而运行新的高优先级进程。相反地，如果一个优先级为49的进程就绪，它会一直等待，直到优先级为50的进程阻塞才可运行。因为普通进程的优先级是0，所以任何就绪的实时进程总会抢占非实时进程，开始运行。

#### 1) 这段话里的“优先级”指的是 **实时优先级（RT priority）**

- 只对 **实时策略**生效：`SCHED_FIFO`、`SCHED_RR`
    
- 取值通常 **1–99**（越大越高）
    
- 是**硬优先级**：  
    只要更高 RT priority 的任务变成 runnable，就会**立刻抢占**正在运行的低优先级任务（包括普通任务）
    

所以你引用的“50 会被 51 立即抢占”描述的是 **RT 调度的抢占规则**。

---

#### 2) nice value 是 **普通调度（CFS）里的权重参数**

- 主要对 `SCHED_OTHER`（以及 `BATCH/IDLE`）有效
    
- nice 常见范围 **-20（更重要）到 +19（更不重要）**
    
- 它不是“硬抢占级别”，而是影响 **CPU 份额/权重**：
    
    - nice 更小 → 权重更大 → 长期平均拿到更多 CPU 时间
        
    - nice 更大 → 权重更小 → 长期平均拿到更少 CPU 时间
        
- 在 CFS 下，并不会出现“nice=0 的进程一定立刻抢占 nice=5 的进程并一直压制它”的那种硬压制关系。
---
#### 进程可以通过sched_getscheduler()和sched_setscheduler()来操作Linux调度策略：
## 1) 函数原型与作用

```C
#include <sched.h>

int sched_getscheduler(pid_t pid);
int sched_setscheduler(pid_t pid, int policy, const struct sched_param *param);
```

### `sched_getscheduler(pid)`

- **作用**：获取指定 `pid` 的调度策略（policy）
    
- **pid==0**：表示当前调用者（当前线程/进程）
    

返回值（成功）是一个策略常量：

- `SCHED_OTHER`（默认/CFS）
    
- `SCHED_FIFO`（实时 FIFO）
    
- `SCHED_RR`（实时 RR）轮询
    
- （也可能有 `SCHED_BATCH`、`SCHED_IDLE`、`SCHED_DEADLINE` 等，视系统支持）
    

失败返回 `-1`，并设置 `errno`（常见 `ESRCH` 进程不存在、`EPERM` 权限不足等）。

---

### `sched_setscheduler(pid, policy, param)`

- **作用**：把指定 `pid` 的调度策略设置为 `policy`，并设置与该策略相关的参数（主要是实时优先级）
    
- **pid==0**：当前调用者
    
- `policy`：要设置成哪种策略
    
- `param`：指向 `struct sched_param`，最重要字段是 `sched_priority`
    

`struct sched_param` 典型长这样：

`struct sched_param {     int sched_priority;   // 实时优先级：对 FIFO/RR 有意义 };`

返回值：

- 成功：`0`
    
- 失败：`-1` 并设置 `errno`（常见 `EPERM/EINVAL/ESRCH`）


----
### 4) 最小示例：先查，再改成 RR(50)，再改回 OTHER
```C
#define _GNU_SOURCE
#include <sched.h>
#include <stdio.h>
#include <errno.h>
#include <string.h>
#include <unistd.h>

static const char* policy_name(int p) {
    switch (p) {
        case SCHED_OTHER: return "SCHED_OTHER";
        case SCHED_FIFO:  return "SCHED_FIFO";
        case SCHED_RR:    return "SCHED_RR";
#ifdef SCHED_BATCH
        case SCHED_BATCH: return "SCHED_BATCH";
#endif
#ifdef SCHED_IDLE
        case SCHED_IDLE:  return "SCHED_IDLE";
#endif
        default: return "UNKNOWN";
    }
}

int main() {
	int RRpri_min = sched_get_priority_min(SCHED_RR);
	int RRpri_max = sched_get_priority_max(SCHED_RR);
	//获取某个人调度策略的优先级范围
	
    pid_t pid = 0; // 当前任务

    int pol = sched_getscheduler(pid);
    if (pol == -1) {
        perror("sched_getscheduler");
        return 1;
    }
    printf("current policy = %s (%d)\n", policy_name(pol), pol);

    // 设为 SCHED_RR，优先级 50（需要权限）
    struct sched_param sp;
    sp.sched_priority = 50;

    if (sched_setscheduler(pid, SCHED_RR, &sp) == -1) {
        printf("sched_setscheduler(RR) failed: %s\n", strerror(errno));
    } else {
        printf("set to SCHED_RR prio=50 OK\n");
    }

    // 改回 SCHED_OTHER（priority 必须为 0）
    sp.sched_priority = 0;
    if (sched_setscheduler(pid, SCHED_OTHER, &sp) == -1) {
        printf("sched_setscheduler(OTHER) failed: %s\n", strerror(errno));
    } else {
        printf("set back to SCHED_OTHER OK\n");
    }

    return 0;
}
```

-----
## 6.7 资源限制（Resource Limits, rlimit / ulimit）

### 6.7.1 rlimit 是什么
rlimit 是内核提供的一种“进程资源上限”机制：
- 限制进程可消耗的某类资源（CPU 时间、文件描述符数、最大文件大小、地址空间等）
- 通常有两档：
  - **soft limit（软限制）**：可触发信号或返回错误
  - **hard limit（硬限制）**：软限制的上限，普通进程不能随意提高
结构体：
```C
struct rlimit{
	rlim_t rlim_cur;//soft limit
	rlim_t rlim_max;//hard limit
}
```


API：
```c
#include <sys/resource.h>
int getrlimit(int resource, struct rlimit *rlim);
int setrlimit(int resource, const struct rlimit *rlim);
```

### 6.7.2 常见 resource 项（高频）
- `RLIMIT_NOFILE`：最多打开文件描述符数（网络服务器特别重要）
- `RLIMIT_NPROC`：用户可创建进程数（防 fork bomb）
- `RLIMIT_CORE`：core dump 最大大小（调试崩溃）
- `RLIMIT_CPU`：CPU 时间上限（超出通常 SIGXCPU）
- `RLIMIT_AS`：虚拟内存地址空间上限
- `RLIMIT_STACK`：栈大小
- `RLIMIT_FSIZE`：单个文件最大大小
- `RLIMIT_MEMLOCK`：可锁定内存上限（实时程序 mlockall 相关）
- `RLIMIT_RTPRIO` / `RLIMIT_RTTIME`：实时相关限制（不同系统支持不同）

#### 最小示例：读取并尝试提高 NOFILE
```C
#include <sys/resource.h>
#include <stdio.h>
#include <errno.h>

int main() {
    struct rlimit lim;
    if (getrlimit(RLIMIT_NOFILE, &lim) < 0) { perror("getrlimit"); return 1; }

    printf("NOFILE cur=%llu max=%llu\n",
           (unsigned long long)lim.rlim_cur,
           (unsigned long long)lim.rlim_max);

    // 尝试把软限制提高到硬限制
    lim.rlim_cur = lim.rlim_max;
    if (setrlimit(RLIMIT_NOFILE, &lim) < 0) { perror("setrlimit"); return 1; }

    return 0;
}
```

### 6.7.3 `ulimit` 与系统配置
- shell 的 `ulimit -n` 影响当前 shell 及其子进程
- 生产上还常需要改：
  - `/etc/security/limits.conf`（pam_limits）
  - systemd service 的 `LimitNOFILE=` 等

### 6.7.4 资源限制在工程中的典型用法
1) **防止资源失控**
- 限制最大打开 fd、防止泄漏拖垮系统
- 限制最大进程数、防止 fork bomb

2) **控制 core dump**
- 线上默认可关（RLIMIT_CORE=0）
- 需要排查崩溃再打开并配合 core_pattern

3) **给实时/高性能程序配置上限**
- 提高 `RLIMIT_NOFILE`，否则 accept/epoll 可能很快撞上上限
- 若要 `mlockall`，需要足够 `RLIMIT_MEMLOCK`

### 6.7.5 补充：cgroups（现代资源治理）
rlimit 是“进程级/用户级”的传统机制。
在容器/服务治理中，更多用 **cgroups** 控 CPU/内存/IO（更强大、可层级管理）。
但学习 rlimit 仍非常重要：它是系统编程里最常见的“自我保护阀门”。

---

# 本章串联：从“写服务程序”的视角看 6.1–6.7

假设你写一个网络服务：
1) `RLIMIT_NOFILE`：先把 fd 上限设置够（或在 systemd 配好）
2) `SIGCHLD + waitpid(WNOHANG)`：避免 worker 退出变僵尸
3) 线程模型：关键线程可考虑 affinity（减少迁移）
4) 普通任务：默认 CFS；对后台维护任务可 `nice(+10)`
5) 只有在严格时延需求下才考虑 RT（并配合 mlockall、避免阻塞）

---

# 快速自测（建议你做完再看答案）

1) `nice` 和实时 priority 有什么本质区别？
2) 为什么 `sched_yield()` 不能替代互斥锁/条件变量？
3) 为什么很多守护进程要提高 `RLIMIT_NOFILE`？
4) affinity 一定能提高性能吗？哪些情况下会变差？

