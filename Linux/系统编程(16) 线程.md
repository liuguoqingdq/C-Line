线程（threading）是指在单个进程内，多路并行执行的创建和管理单元。由于线程引入了数据竞争和死锁，其相关的编程错误不计其数。关于线程这一主题是以写一本书，而且确实已经有了这样的书。这些书主要关注某个特定于线程库提供的各种接口函数。

在本章，我们将涵盖Linux线程API的基础知识，重点在于探讨以下几个问题：
- 在系统编程人员的工具箱中，线程有何作用？
- 为什么要使用线程？
- 以及更重要的一点，为什么不使用线程？
- 哪些设计模式可以帮助我们抽象并构建“线程密集型”应用？
- 最后一点，什么是数据竞争以及如何避免竞争？
---
## 1）二进制程序（可执行文件）是什么？

**二进制程序**是磁盘上的一个文件（比如 `/bin/ls`、你编译出来的 `a.out`），里面包含：

- 可执行代码（机器指令）
    
- 数据段（全局变量、常量等）
    
- ELF 头、段表/节表等元信息（Linux 常见是 ELF 格式）
    
- 动态链接信息（需要哪些 `.so`、入口点在哪里等）
    

它的本质是：**“静态的程序映像（program image）”**，还没运行。

### 关键点

- 同一个二进制文件可以被运行很多次（每次都产生不同的进程）。
    
- 文件权限位（`x`、setuid/setgid）属于“二进制文件”，影响“运行它时进程获得什么身份”。
    

---

## 2）进程（process）是什么？

**进程**是二进制程序“运行起来之后”的一个实例，是内核管理的一个“执行环境”。它至少拥有：

- **独立的虚拟地址空间**（代码段/堆/栈/映射区）
    
- 打开的文件描述符表（fd：0/1/2 …）
    
- 当前工作目录、root 目录、环境变量等
    
- 身份凭据（UID/GID、capabilities）
    
- 信号处理方式、资源限制（rlimit）
    
- 一个或多个线程（现代 Linux 下，一个进程至少有 1 个线程）
    

### 进程最核心的特征

> **资源容器 + 地址空间**  
> 进程把“内存、fd、权限、信号、资源限制”等打包成一个整体。

---

## 3）线程（thread）是什么？

**线程**是进程内部的执行流（execution flow）。同一进程的多个线程：

- **共享同一个进程地址空间**（同一堆、同一全局变量、同一 mmap 区）
    
- **共享同一个 fd 表**（一个线程 `close(fd)` 影响所有线程）
    
- 共享多数进程级属性（cwd、信号处置、rlimit 等）
    

但每个线程**自己独有**：

- **线程栈**（stack）
    
- 寄存器上下文（PC/IP、SP、通用寄存器）
    
- 线程局部存储（TLS）
    
- 调度实体（在 Linux 里，线程也是调度单位）
    

### Linux 的关键事实（系统编程最重要）

> Linux 内核调度的基本单位是 **task（任务）**，线程在内核层面就是一个 task。  
> 一个“进程”在内核里通常表现为“一组共享资源的 task”（线程组）。

---
## 4）三者关系：一句话版 + 图

- **二进制程序**：磁盘上的“可执行文件”
    
- **进程**：这个程序运行后的“资源容器/地址空间实例”
    
- **线程**：进程内部的“执行流”，是 CPU 实际调度的对象
```lua
磁盘：ELF 可执行文件（binary）
          |
       execve
          v
内存：进程（地址空间 + 资源）
          |
        pthread_create
          v
线程1、线程2、线程3 ...（共享进程资源，各自有栈/寄存器）

```

---
## 5）系统调用层面的对应（你写代码时怎么映射）

### 二进制 → 进程

- `fork()`：复制出一个新进程（几乎共享起步，COW）
    
- `execve()`：用另一个二进制程序“替换”当前进程映像（PID 不变，但代码/数据换了）
    

### 进程 → 线程

- `pthread_create()`（用户态 API）底层常用 `clone()` 系统调用创建线程
    
- `exit()` / `_exit()`：结束进程（结束整个地址空间）
    
- `pthread_exit()`：结束当前线程（进程里可能还有其它线程）

----
## 多线程

那么，为什么要有线程呢？显然，我们需要进程，因为它们是正在运行的程序的抽象。但是，为什么要分离执行单元，引入线程？多线程机制提供了六大好处：

- **编程抽象** 
	把工作切分成多个模块，并为每个分块分配一个执行单元（线程）是解决很多问题的常见方式。利用这种方法的设计模式包括“每个连接一个线程”和线程池模式。编程人员觉得这些模式有用且直观。但是，有些人觉得线程破坏了模式理念。Alan Cox曾提出这样的说法——“线程是为那些不会使用状态机编程的人设计的”。也就是说，从理论上而言，所有可通过线程解决的编程问题都可以通过状态机解决。 
 - **并发性** 
	 对于有多个处理器的计算机，线程提供了一种实现“真正并发”的高效方式。每个线程有自己的虚拟处理器，是作为独立的调度实体，因此在多个处理器上可以同时运行多个线程，从而提高系统的吞吐量。由于线程可以实现并发性——也就是说，线程数小于等于处理器数——前面提到的“线程是为那些不会使用状态机编程的人设计的”的说法是不成立的。
- **提高响应能力** 
	 即使是在单处理器的计算机上，多线程也可以提高进程的响应能力。在单线程的进程中，一个长时间运行的任务会影响应用对用户输入的响应，导致应用看起来“僵死”了。有了多线程机制，这些操作可以委托给worker线程，至少有一个线程可以响应用户输入并执行UI操作。 
 - **I/O阻塞** 
	 这和前一项“提高响应能力”紧密相关。如果没有线程，I/O阻塞会影响整个进程。这对吞吐量和延迟都是灾难。在多线程的进程中，单个线程可能会因I/O等待而阻塞，而其他线程可以继续执行。除了线程之外，异步I/O和非阻塞I/O也是这种问题的解决方案。 
 - **上下文切换** 
	 在同一个进程中，从一个线程切换到另一个线程的代价要显著低于进程间的上下文切换。 
 - **内存保存** 
	 线程提供了一种可以共享内存，并同时利用多个执行单元的高效方式。从这个角度看，多线程在某些场景下可以取代多进程。

---
## 多线程的代价

## 1) 正确性代价：并发 bug 难且隐蔽

### A. 竞态条件（race condition）

共享数据没同步，结果取决于“谁先跑”，表现为：

- 偶发崩溃、偶发数据错、线上很难复现
    
- 加日志/调试反而“消失”（时序被改变）
    

### B. 内存可见性与重排序

即使“没崩”，也可能读到旧值/乱序结果：

- CPU 缓存、编译器优化会导致读写看起来“没按你写的顺序发生”
    
- 需要原子操作/内存序/锁来建立 happens-before
    

### C. 死锁（deadlock）

常见成因：

- 锁顺序不一致（A 先锁1再锁2，B 先锁2再锁1）
    
- 锁内调用外部代码/IO，导致不可控等待
    

### D. 活锁（livelock）与饥饿（starvation）

- 活锁：大家都在“让路/重试”，但谁都不前进
    
- 饥饿：某线程长期拿不到锁或 CPU（尤其是优先级不当、锁竞争激烈时）
    

### E. 优先级反转（priority inversion）

低优先级线程拿着锁，高优先级线程被迫等待，调度上反而变慢。需要优先级继承等机制（不是所有锁都默认解决）。

---

## 2) 性能代价：线程多 ≠ 更快，常常更抖

### A. 上下文切换开销

线程越多、越频繁抢占/阻塞，切换越多：

- 保存/恢复寄存器、调度开销
    
- cache/TLB 失效 → 性能下降、尾延迟上升
    

### B. 锁竞争与串行化

线程多但都抢同一把锁：

- 变成“排队系统”，吞吐不升反降
    
- 典型现象：CPU 很忙但有效工作很少
    

### C. 惊群效应（thundering herd）

一个事件唤醒一堆线程，最后只有一个能拿到资源，其他又睡回去：

- 无谓唤醒 + 争锁 + 切换
    

### D. 伪共享（false sharing）

不同线程写不同变量，但落在同一个 cache line：

- 造成 cache line 来回抖动，性能极差
    
- 需要 padding/对齐/分桶计数等手段
    

### E. 负载不均衡与迁移抖动

- 线程工作量不均导致某些核忙某些核闲
    
- 线程频繁迁移 CPU，cache 热度丢失，抖动变大
    
- 绑核/合理线程数/工作窃取可缓解，但又增加复杂度
    

---

## 3) 资源代价：线程本身要“吃”系统资源

### A. 每个线程都有栈

- 默认栈可能很大（例如 pthread 默认栈常见是 MB 级，依系统/配置不同）
    
- 线程多时虚拟地址空间/内存压力明显增大
    

### B. 内核对象与调度开销

- 每个线程都是一个调度实体（task），会增加 runqueue 管理、调度器工作量
    
- 线程数爆炸会让系统整体变慢甚至不可用
    

### C. 可观测性/诊断复杂

- 一个进程上百线程：堆栈、日志、火焰图、死锁定位都更难
    
- 需要更规范的 trace、指标、线程命名、统一日志上下文
    

---

## 4) 工程代价：代码复杂度与维护成本上升

- API 必须线程安全：对象生命周期、引用计数、并发容器
    
- 测试成本高：需要压力测试、竞态检测（TSan 等）、故障注入
    
- 架构约束更多：锁层级、不可重入、回调死锁等“规约”必须长期维护
    

---

## 5) 一个系统编程的“经验结论”

**多线程真正的价值是：并行 + 重叠 I/O 与 CPU**，但它带来的最大痛点是：

- **尾延迟（P99/P999）变差**
    
- **bug 复现困难**
    
- **性能不升反降**
    

所以实践里通常的策略是：

- 先用少量线程/清晰的线程模型（I/O 线程 + worker 线程池）
    
- 尽量减少共享状态（消息队列/无共享架构）
    
- 锁要短、锁顺序统一、避免锁内 I/O
    
- 线程数不要盲目跟核数翻倍，先测再调


----
## 多线程模型
## 1) 用户级线程模型（User-Level Threads，M:1）

### 是什么

- **M:1**：很多用户线程（M）映射到 **1 个内核线程**（1）。
    
- 调度完全在用户态：用户线程库自己决定哪个用户线程运行。
    

你可以把它理解成：**“在一个 OS 线程里跑很多‘小线程’，靠用户态调度器切换”**（也叫 _green threads_）。

### 在 Linux 上怎么工作

- 内核只看到 **一个可调度实体（一个 kernel task）**。
    
- 用户态线程切换一般是：
    
    - 保存/恢复寄存器
        
    - 切换栈指针（每个用户线程一段用户栈）
        
    - 跳转到另一个执行点  
        常见实现方式：`ucontext`/`setjmp+longjmp`/手写汇编上下文切换/fiber 库等。
        

### 优点

- **切换很快**：不需要陷入内核，不涉及内核调度。
    
- **创建销毁便宜**：不需要创建内核线程对象。
    
- **可控性强**：你能自定义调度策略（优先级、时间片、协作式等）。
    

### 缺点（最关键）

- **阻塞系统调用会“卡死整个进程”**：因为内核只看到一个线程，这个线程一旦 `read()`/`accept()` 阻塞，所有用户线程都停了。
    
- **不能真正利用多核并行**：只有一个内核线程，最多用到一个 CPU 核的时间片（除非你再起多个内核线程，那就变成 M:N 思路了）。
    
- 信号、调试、栈回溯等更复杂（因为内核不知道你的用户线程）。
    

### 典型适用

- 计算协作型、不会做阻塞 syscall，或你能把 I/O 做成非阻塞 + 事件驱动的场景。
    
- 教学/实验/某些特殊 runtime。
    

---

## 2) 混合式线程模型（Hybrid，M:N）

### 是什么

- **M:N**：M 个用户线程，映射到 N 个内核线程上运行。
    
- 用户态负责“用户线程调度”，内核负责“把 N 个内核线程分配到 CPU”。
    

你可以把它理解成：**“用户态有一堆任务（用户线程），下面有一个内核线程池在跑它们”**。

### 在 Linux 上怎么工作

- 内核看到 N 个可调度实体（N 个 kernel threads）。
    
- 每个内核线程上跑一个用户态调度循环（scheduler loop），从 runnable 的用户线程队列里取一个执行。
    
- 为了避免阻塞 syscall 卡死全部，常见做法：
    
    1. **I/O 走非阻塞 + epoll**：调度器只在用户线程可运行时切换进去。
        
    2. **阻塞 I/O 下沉到专门的内核线程**：把可能阻塞的操作丢给一个“blocking pool”，避免占用执行用户线程的内核线程。
        
    3. 使用异步接口（在 Linux 上更多是事件驱动而非传统 AIO）。
        

### 优点

- **能用多核**：N 个内核线程可并行跑在多个 CPU 上。
    
- **仍然能享受用户态线程的轻量切换**：M 个任务比 N 个内核线程轻得多。
    
- **对阻塞更有弹性**：一个内核线程阻塞，不至于全体停摆（还剩 N-1 个在跑）。
    

### 缺点

- **实现复杂**：用户态调度 + 内核调度叠加，队列、负载均衡、抢占点、信号、TLS 都更难。
    
- **“两级调度”问题**：用户态不知道内核什么时候把某个内核线程挂起；内核也不知道哪个用户线程更关键，可能导致不理想的调度互动。
    
- 调试/性能分析更难（你得同时理解 runtime 和内核调度）。
    

### 典型适用

- 语言/运行时（runtime）级并发：例如某些语言的 runtime 用类似思路管理大量任务（概念上）。
    
- 高并发服务：希望“任务很多但 OS 线程不要爆炸”，又希望多核并行。
    

---

## 3) 协同程序/协程（Coroutine / Cooperative routine）

你说的“协同程序”在系统编程里一般对应：**协作式调度的用户态执行单元**（常被实现为协程/fiber）。

### 是什么

- 协程是“可以挂起/恢复”的函数执行单元。
    
- **协作式（cooperative）**：不会被强制抢占，只有在你写的 `yield/await` 等挂起点才切换。
    

> 协程本质上是“更结构化的用户态切换机制”；它可以运行在：
> 
> - 单个内核线程上（M:1）
>     
> - 或运行在 M:N runtime 的某个内核线程上（每个内核线程里跑很多协程）
>     

### 优点

- **切换更轻**：通常比线程更轻量。
    
- **避免共享数据的抢占并发**：协作式切换点明确，很多场景锁更少（但不是不需要）。
    
- **非常适合 I/O 密集的并发**：`epoll` 驱动 + 协程 `await`，写起来接近同步代码，运行是异步。
    

### 缺点

- **只要你不让出，就会饿死别人**：一个协程 CPU 忙循环，不 `yield/await`，其它协程没机会跑（在同一 OS 线程内）。
    
- **阻塞 syscall 仍是大忌**：如果协程跑在一个 OS 线程上，做阻塞调用会卡住同线程内所有协程（除非 runtime 把阻塞 I/O 下沉到别的线程）。
    
- **多核并行取决于底层有多少 OS 线程**：单线程协程不能并行，只能并发。
    

### 典型适用

- 高并发网络程序：大量连接、每个连接逻辑较清晰（async/await 风格）。
    
- 需要低开销并发但又不想线程爆炸的场景。
    

---

## 一张对照表：你最关心的点

|模型|内核看到的线程数|切换发生在哪|阻塞 syscall 影响|多核并行|典型形态|
|---|---|---|---|---|---|
|用户级线程 M:1|1|用户态|卡死整个进程|否|green threads|
|混合 M:N|N|用户态 + 内核态|卡住一个内核线程，其它还能跑|是|runtime 调度器 + OS 线程池|
|协程（协作式）|取决于承载它的 OS 线程数|用户态|同一 OS 线程内全卡（除非下沉）|取决于 OS 线程数|async/await、fiber|

---
## 线程模式
## 1）一线程一连接（Thread-per-Connection）

每个连接对应一个线程”是一种编程模式，在该模式中，每个工作单元被分配给一个线程，而该线程在该工作单元执行期间，不会被分配给其他工作单元。工作单元是指如何分解应用的工作：请求、连接等。在这里，我们将“连接”作为描述该模式的通用术语。

### 结构

- `accept()` 一个连接 → `pthread_create()` 创建一个线程专门处理这个连接
    
- 每个线程用阻塞 I/O：`read/write` 或 `recv/send`
    

### 优点

- 代码直观：一个连接就是一条顺序逻辑
    
- 同步简单（每个连接状态在线程栈上）
    

### 缺点（系统编程里最致命）

- 连接数上千上万时：线程数爆炸
    
    - 栈内存占用大
        
    - 上下文切换剧增
        
    - 锁竞争/调度抖动明显
        
- `accept` 峰值时容易“打爆”系统
    

### 适用

- 连接数小、逻辑复杂但并发不高（管理后台、内网工具）
    
- 或者用在“短连接、低并发”的场合
    

### 相关 API

`pthread_create`, `pthread_join`, 阻塞 socket I/O

---

## 2）事件驱动单线程（Single-thread Reactor / 单线程 epoll）

### 结构

- 一个线程（或极少线程）负责所有连接
    
- 所有 socket 设为 non-blocking
    
- 核心循环：
    
    - `epoll_wait()` 得到就绪 fd
        
    - 对就绪 fd 进行 `recv/send`（注意 EAGAIN）
        
    - 用状态机管理每个连接的读写状态
        

### 优点

- 极省线程：几万连接也不需要几万线程
    
- 上下文切换少，性能稳定
    
- 对 I/O 密集型服务非常友好（nginx 的典型思想）
    

### 缺点

- 编程复杂：必须写状态机、处理半包、处理边缘触发等
    
- **CPU 密集任务**会阻塞事件循环，导致所有连接延迟上升（“一慢全慢”）
    

### 适用

- 高并发、I/O 密集、每次处理不重（反向代理、网关、推送、IM）
    

### 相关 API

`epoll_create1/epoll_ctl/epoll_wait`、`fcntl(O_NONBLOCK)`、非阻塞 socket

----
## Pthreads

### 一、链接pthread库
```C
gcc -Wall -pthread main.cpp
```

[[Pthreads库]]
---

### 二、创建线程

###### `phtread_create系统调用:`

```C
int pthread_create(pthread_t *thread,
                   const pthread_attr_t *attr,
                   void *(*start_routine)(void *),
                   void *arg);

```

